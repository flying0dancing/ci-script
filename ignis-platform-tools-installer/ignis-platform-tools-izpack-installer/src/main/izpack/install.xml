<?xml version="1.0" encoding="UTF-8"?>
<izpack:installation version="5.0"
                     xmlns:izpack="http://izpack.org/schema/installation"
                     xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                     xsi:schemaLocation="http://izpack.org/schema/installation http://izpack.org/schema/5.1/izpack-installation-5.1.xsd">

  <info>
    <appname>FCR Engine - Platform Tools</appname>
    <appversion>@{izpack.app.version}</appversion>
    <javaversion>1.8</javaversion>
    <uninstaller write="no" />
    <writeinstallationinformation>no</writeinstallationinformation>
    <summarylogfilepath>${INSTALL_PATH}/logs</summarylogfilepath>
    <url>https://www.vermeg.com/</url>
  </info>

  <jar src="@{izpack.staging.platform-tools.jar}" stage="install" />

  <guiprefs height="600" width="800" resizable="yes" />

  <locale>
    <langpack iso3="eng" />
  </locale>

  <resources>
    <res id="userInputLang.xml" src="lang/userInputLang.xml" />
    <res id="userInputSpec.xml" src="panel/userInputSpec.xml" type="xml" />
  </resources>

  <conditions>
    <condition id="isStandalone" type="variable">
      <name>distributed</name>
      <value>false</value>
    </condition>
    <condition id="isDistributed" type="variable">
      <name>distributed</name>
      <value>true</value>
    </condition>
  </conditions>

  <variables>
    <!--shared config-->
    <variable name="distributed"
              value="false" />
    <variable name="SSH_OPTS"
              value="" />
    <variable name="hosts"
              value="" />
    <variable name="hadoop.user"
              value="${USER_NAME}" />

    <!--zookeeper config-->
    <variable name="zookeeper.hosts"
              value="${HOST_NAME}" />
    <variable name="zookeeper.client.port"
              value="2181" />
    <variable name="zookeeper.myid"
              value="1" />

    <!--hdfs config-->
    <variable name="hdfs.nn.host"
              value="${HOST_NAME}" />
    <variable name="hdfs.nn.ui.port"
              value="50070" />
    <variable name="hdfs.nn.port"
              value="9000" />
    <variable name="hdfs.sn.host"
              value="${HOST_NAME}" />
    <variable name="hdfs.dn.hosts"
              value="${HOST_NAME}" />
    <variable name="hdfs.sn.ui.port"
              value="50090" />
    <variable name="hdfs.dn.ui.port"
              value="50075" />

    <!--yarn config-->
    <variable name="yarn.rm.host"
              value="${HOST_NAME}" />
    <variable name="yarn.rm.port"
              value="8088" />
    <variable name="yarn.nm.hosts"
              value="${HOST_NAME}" />
    <variable name="yarn.nm.port"
              value="8042" />
    <variable name="history.server.host"
              value="${HOST_NAME}" />
    <variable name="history.server.port"
              value="19888" />

    <variable name="yarn.nodemanager.pmem-check-enabled"
              value="false" />
    <variable name="yarn.nodemanager.vmem-check-enabled"
              value="false" />

    <variable name="yarn.nodemanager.resource.memory-mb"
              value="8192" /><!--unit is M-->
    <variable name="yarn.nodemanager.resource.cpu-vcores"
              value="4" />

    <!--hbase config-->
    <variable name="hbase.master.host"
              value="${HOST_NAME}" />
    <variable name="hbase.master.port"
              value="16010" />
    <variable name="hbase.regionserver.hosts"
              value="${HOST_NAME}" />
    <variable name="hbase.regionserver.port"
              value="16030" />
    <variable name="hbase.backup.master.hosts"
              value="" />

    <variable name="dfs.replication"
              value="1" />
    <variable name="hbase.client.write.buffer"
              value="8388500" /><!--unit is byte-->
    <variable name="hbase.regionserver.handler.count"
              value="32" />
    <variable name="dfs.client.hedged.read.threadpool.size"
              value="8" />
    <variable name="dfs.client.hedged.read.threshold.millis"
              value="30" />
    <variable name="dfs.client.read.shortcircuit"
              value="true" />
    <variable name="hbase.bucketcache.size"
              value="64" />

    <variable name="hbase.hregion.memstore.flush.size"
              value="134217728" />
    <variable name="hbase.heapsize"
              value="4G" />
    <variable name="hbase.offheapsize"
              value="1G" />

    <!--phoenix config-->
    <variable name="phoenix.qs.hosts"
              value="${HOST_NAME}" />
    <variable name="phoenix.qs.port"
              value="8765" />

    <!--spark config-->
    <variable name="spark.history.server.host"
              value="${HOST_NAME}" />
    <variable name="spark.history.server.port"
              value="18080" />
    <variable name="spark.eventLog.compress"
              value="true" />
  </variables>


  <dynamicvariables>
    <!--shared config-->
    <variable name="izpack.dist.zookeeper.dir"
              value="@{izpack.dist.zookeeper.dir}" />
    <variable name="izpack.dist.hadoop.dir"
              value="@{izpack.dist.hadoop.dir}" />
    <variable name="izpack.dist.hbase.dir"
              value="@{izpack.dist.hbase.dir}" />
    <variable name="izpack.dist.phoenix.dir"
              value="@{izpack.dist.phoenix.dir}" />
    <variable name="izpack.dist.spark.dir"
              value="@{izpack.dist.spark.dir}" />

    <variable name="INSTALLER_PATH"
              value="${SYSTEM[INSTALLER_PATH]}" />

    <variable name="FCR_ENGINE_HOME"
              value="${INSTALL_PATH}/../.." />
    <variable name="DATA_PATH"
              value="${FCR_ENGINE_HOME}/data" />
    <variable name="tmp.path"
              value="${DATA_PATH}/../tmp" />

    <variable name="ZOOKEEPER_HOME"
              value="${INSTALL_PATH}/@{izpack.dist.zookeeper.dir}" />
    <variable name="HADOOP_HOME"
              value="${INSTALL_PATH}/@{izpack.dist.hadoop.dir}" />
    <variable name="HBASE_HOME"
              value="${INSTALL_PATH}/@{izpack.dist.hbase.dir}" />
    <variable name="PHOENIX_HOME"
              value="${INSTALL_PATH}/@{izpack.dist.phoenix.dir}" />
    <variable name="SPARK_HOME"
              value="${INSTALL_PATH}/@{izpack.dist.spark.dir}" />

    <!--shared hadoop config-->
    <variable name="fs.defaultFS"
              value="hdfs://${hdfs.nn.host}:${hdfs.nn.port}" />

    <!--hadoop config-->
    <variable name="dfs.namenode.name.dir"
              value="file://${DATA_PATH}/hdfs/namenode" />
    <variable name="dfs.datanode.data.dir"
              value="file://${DATA_PATH}/hdfs/datadata" />
    <variable name="dfs.namenode.checkpoint.dir"
              value="file:///${DATA_PATH}/hdfs/sname" />

    <!--yarn config-->
    <variable name="yarn.log.server.url"
              value="http://${history.server.host}:${history.server.port}/jobhistory/logs" />

    <!--hbase config-->
    <variable name="hbase.rootdir"
              value="${fs.defaultFS}/hbase" />

    <!--spark config-->
    <variable name="spark.eventLog.dir"
              value="hdfs://${hdfs.nn.host}:${hdfs.nn.port}/spark/app-logs" />

    <variable name="spark.yarn.historyServer.address"
              value="${spark.history.server.host}:${spark.history.server.port}" />

    <variable name="dfs.replication"
              condition="isDistributed"
              value="3" />
    <variable name="dfs.replication"
              condition="isStandalone"
              value="1" />
  </dynamicvariables>

  <panels>
    <!--Shows App Info-->
    <panel classname="HelloPanel" />

    <!--Sets $INSTALL_PATH-->
    <panel classname="TargetPanel">
      <validator classname="com.izforge.izpack.installer.validator.ConditionValidator" />
      <validator classname="com.lombardrisk.ignis.izpack.panel.validation.InstallerStructureValidator" />
    </panel>

    <panel classname="UserInputPanel" id="panel.install.mode" />

    <panel classname="UserInputPanel" id="panel.allocate.hosts" condition="isDistributed">
      <validator classname="com.lombardrisk.ignis.platform.tools.izpack.panel.validation.HostsValidator" />
      <validator classname="com.lombardrisk.ignis.platform.tools.izpack.panel.validation.LocalHostAddressValidator" />

      <actions>
        <action stage="preconstruct"
                classname="com.lombardrisk.ignis.platform.tools.izpack.panel.action.LoadHostsAction" />
        <action stage="postvalidate"
                classname="com.lombardrisk.ignis.platform.tools.izpack.panel.action.AssignHostsAction" />
      </actions>
    </panel>

    <panel classname="UserInputPanel" id="panel.assign.master" condition="isDistributed">
      <validator classname="com.lombardrisk.ignis.platform.tools.izpack.panel.validation.HBaseHostValidator" />
      <validator classname="com.lombardrisk.ignis.platform.tools.izpack.panel.validation.ZookeeperHostsValidator" />

      <actions>
        <action stage="preactivate"
                classname="com.lombardrisk.ignis.platform.tools.izpack.panel.action.LoadServerIpAction" />
        <action stage="postvalidate"
                classname="com.lombardrisk.ignis.platform.tools.izpack.panel.action.ConfigZooKeeperAction" />
      </actions>
    </panel>

    <panel classname="UserInputPanel" id="panel.assign.secondary" condition="isDistributed">
      <actions>
        <action stage="preactivate"
                classname="com.lombardrisk.ignis.platform.tools.izpack.panel.action.LoadServerIpAction" />
      </actions>
    </panel>

    <!--Copies Distributions And Runs Installation Packs-->
    <panel classname="InstallPanel">
      <actions>
        <action stage="preactivate" classname="com.lombardrisk.ignis.izpack.panel.action.CopyDistributionDirsAction" />
      </actions>
    </panel>

    <panel classname="SimpleFinishPanel" />
  </panels>

  <packs>
    <pack name="Current Configuration Setup" required="true">
      <description>Save configuration</description>

      <fileset dir="."
               targetdir="${INSTALL_PATH}"
               includes="system.properties"
               override="true" />

      <parsable type="plain">
        <fileset targetdir="${INSTALL_PATH}"
                 includes="system.properties" />
      </parsable>
    </pack>

    <pack name="Shared Config Setup" required="true">
      <description>Setup shared config</description>

      <fileset dir="bin"
               targetdir="${INSTALL_PATH}/bin"
               override="true" />
      <fileset dir="conf"
               targetdir="${INSTALL_PATH}/conf"
               override="true" />

      <parsable type="shell">
        <fileset targetdir="${INSTALL_PATH}/conf"
                 includes="**/*.sh" />
        <fileset targetdir="${INSTALL_PATH}/bin"
                 includes="**/*.sh,**/*.service" />
      </parsable>
    </pack>

    <pack name="@{izpack.dist.zookeeper.dir} Setup" required="true">
      <description>Setup @{izpack.dist.zookeeper.dir}</description>

      <fileset dir="@{izpack.dist.zookeeper.dir}/conf"
               targetdir="${ZOOKEEPER_HOME}/conf"
               includes="zoo.cfg"
               override="true" />
      <fileset dir="data/zookeeper"
               targetdir="${DATA_PATH}/zookeeper"
               includes="myid"
               override="true" />

      <parsable type="plain">
        <fileset targetdir="${ZOOKEEPER_HOME}/conf"
                 includes="zoo.cfg" />
      </parsable>
      <parsable type="plain">
        <fileset targetdir="${DATA_PATH}/zookeeper"
                 includes="myid" />
      </parsable>
    </pack>

    <pack name="@{izpack.dist.hadoop.dir} Setup" required="true">
      <description>Setup @{izpack.dist.hadoop.dir} configuration</description>

      <fileset dir="@{izpack.dist.hadoop.dir}/etc/hadoop"
               targetdir="${HADOOP_HOME}/etc/hadoop"
               includes="@{izpack.hadoop.config.files}"
               override="true" />

      <parsable type="shell" encoding="UTF-8">
        <fileset targetdir="${HADOOP_HOME}/etc/hadoop"
                 includes="@{izpack.hadoop.config.files}" />
      </parsable>
    </pack>

    <pack name="@{izpack.dist.hbase.dir} Setup" required="true">
      <description>Setup @{izpack.dist.hbase.dir}</description>

      <fileset dir="@{izpack.dist.hbase.dir}/conf"
               targetdir="${HBASE_HOME}/conf"
               includes="@{izpack.hbase.config.files}"
               override="true" />

      <parsable type="shell" encoding="UTF-8">
        <fileset targetdir="${HBASE_HOME}/conf"
                 includes="@{izpack.hbase.config.files}" />
      </parsable>
    </pack>

    <pack name="@{izpack.dist.phoenix.dir} Setup" required="true">
      <description>Setup @{izpack.dist.phoenix.dir}</description>

      <fileset dir="@{izpack.dist.phoenix.dir}/bin"
               targetdir="${PHOENIX_HOME}/bin"
               includes="@{izpack.phoenix.config.files}"
               override="true">
      </fileset>

      <parsable type="shell" encoding="UTF-8">
        <fileset targetdir="${PHOENIX_HOME}/bin/config"
                 includes="env.sh" />
      </parsable>
    </pack>

    <pack name="@{izpack.dist.spark.dir} Setup" required="true">
      <description>Setup @{izpack.dist.spark.dir}</description>

      <fileset dir="@{izpack.dist.spark.dir}/conf"
               targetdir="${SPARK_HOME}/conf"
               includes="@{izpack.spark.config.files}"
               override="true" />

      <parsable type="shell" encoding="UTF-8">
        <fileset targetdir="${SPARK_HOME}/conf"
                 includes="@{izpack.spark.config.files}" />
      </parsable>
    </pack>

    <pack name="Run Post-Install Setup" required="true">
      <description>Run post-install setup</description>

      <file src="post-install.sh"
            targetdir="${INSTALL_PATH}"
            override="true" />

      <executable type="bin" stage="postinstall" keep="false"
                  targetfile="${INSTALL_PATH}/post-install.sh"
                  failure="abort">
        <os family="unix" />
      </executable>
    </pack>
  </packs>
</izpack:installation>